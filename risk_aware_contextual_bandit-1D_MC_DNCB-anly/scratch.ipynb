{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cb01f804-c486-4478-9308-5a52e9dc7ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "class csv_handler:\n",
    "    def __init__(self, filename, fieldnames):\n",
    "        self.fieldnames = fieldnames\n",
    "        file_exists = os.path.isfile(filename) \n",
    "        self.f = open(filename, 'a', newline='')\n",
    "        self.csv_writer = csv.DictWriter(self.f, fieldnames=fieldnames, delimiter=',')\n",
    "        if not file_exists:\n",
    "            self.csv_writer.writeheader()\n",
    "\n",
    "    def addLine(self, in_dict):\n",
    "        if len(in_dict.keys()) != len(self.fieldnames):\n",
    "            print(in_dict.keys())\n",
    "            print(in_dict)\n",
    "            print(self.fieldnames)\n",
    "        \n",
    "        assert len(in_dict.keys()) == len(self.fieldnames)\n",
    "        self.csv_writer.writerow(in_dict)\n",
    "        self.f.flush()\n",
    "\n",
    "    def close_csv(self):\n",
    "        self.f.close()\n",
    "\n",
    "\n",
    "\n",
    "class EnvTank:\n",
    "    def __init__(self, algo, noise, create_log=1, timestamp='', save_contexts=0, contexts_file='', ver=1):\n",
    "        \n",
    "        assert noise is not None\n",
    "        self.noise_dist = noise['dist']\n",
    "        self.noise_var = noise['var']\n",
    "        self.create_log = create_log\n",
    "        self.save_contexts = save_contexts\n",
    "        self.algo = algo\n",
    "        self.version = ver\n",
    "        \n",
    "        ### START KINEMATICS\n",
    "        self.vel = 1000\n",
    "        self.grav = -9.81\n",
    "\n",
    "        self.elmin = np.deg2rad(0)\n",
    "        velrgdistmin = self.vel * np.cos(self.elmin)\n",
    "        velhtdistmin = self.vel * np.sin(self.elmin)\n",
    "        t_distmin = np.roots([0.5 * self.grav, velhtdistmin, 0])[0]\n",
    "        self.distmin = velrgdistmin * t_distmin\n",
    "\n",
    "        self.elopt = np.deg2rad(45)\n",
    "        velrgopt = self.vel * np.cos(self.elopt)\n",
    "        velhtopt = self.vel * np.sin(self.elopt)\n",
    "        self.t_distmax = np.roots([0.5 * self.grav, velhtopt, 0])[0]\n",
    "        self.distmax = velrgopt * self.t_distmax\n",
    "\n",
    "        self.elmax = np.deg2rad(90)\n",
    "        velhtmax = self.vel * np.sin(self.elmax)\n",
    "        self.t_max = np.roots([0.5 * self.grav, velhtmax, 0])[0]\n",
    "        ### END KINEMATICS\n",
    "        \n",
    "        self.step_counter = 0\n",
    "        min_action, max_action, action_dim = 0, 2 * self.elmax, 1\n",
    "        # min_action, max_action, action_dim = 0, self.elmax, 1\n",
    "        min_obs, max_obs = -0.5 * self.distmax, 0.5 * self.distmax\n",
    "        self.obs_dim = 2 if self.version == 2 else 1\n",
    "        \n",
    "        self.action_space = spaces.Box(low=min_action, high=max_action, shape=(action_dim,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=min_obs, high=max_obs, shape=(self.obs_dim,), dtype=np.float32)\n",
    "        \n",
    "        # self.obs = self.observation_space.sample()\n",
    "        self.get_obs()\n",
    "                \n",
    "        self.timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\") if timestamp=='' else timestamp\n",
    "        self.path = os.path.join(os.getcwd(), 'results', self.timestamp)\n",
    "        \n",
    "        if self.save_contexts:\n",
    "            assert len(contexts_file) == 0\n",
    "            fieldnames = ['step', 'context0', 'context1']\n",
    "            filename = os.path.join(self.path, self.timestamp+'_context_log.csv')\n",
    "            os.makedirs(self.path, exist_ok=True)\n",
    "            self.csv_h_contexts = csv_handler(filename, fieldnames)\n",
    "            \n",
    "            # context2 = self.obs[2] if self.version == 2 else -1\n",
    "            measure = {'step' : self.step_counter, 'context0' : self.obs[0], 'context1': self.obs[1]}\n",
    "            self.csv_h_contexts.addLine(measure)\n",
    "            \n",
    "        self.reset(contexts_file)\n",
    "\n",
    "\n",
    "    def get_obs(self):\n",
    "        self.obs = self.observation_space.sample()\n",
    "        obs0 = self.obs[0]\n",
    "        obs1 = self.obs[1]\n",
    "        if obs0 > obs1:\n",
    "            self.obs[0] = obs1\n",
    "            self.obs[1] = obs0\n",
    "\n",
    "\n",
    "    def reset(self, contexts_file=''):\n",
    "        \n",
    "        if self.create_log:\n",
    "            fieldnames = ['step', 'context', 'action', 'reward', 'constraint_1', 'alpha']\n",
    "            filename = os.path.join(self.path, self.timestamp+f'_{self.algo}_log.csv')\n",
    "            os.makedirs(self.path, exist_ok=True)\n",
    "            self.csv_h = csv_handler(filename, fieldnames)\n",
    "        \n",
    "        \n",
    "        if len(contexts_file) > 0:\n",
    "            with open(contexts_file) as in_file:\n",
    "                self.n_lines = sum(1 for _ in in_file)\n",
    "            \n",
    "            self.f = open(contexts_file)\n",
    "            self.contexts_file = csv.reader(self.f, delimiter=',')\n",
    "            next(self.contexts_file)\n",
    "            line = next(self.contexts_file)\n",
    "            self.obs = np.zeros(self.obs_dim)\n",
    "            \n",
    "            for i in range(self.obs_dim):\n",
    "                self.obs[i] = float(line[i+1])\n",
    "        else:\n",
    "            self.contexts_file = None\n",
    "    \n",
    "    def close(self):\n",
    "        if self.create_log:\n",
    "            self.csv_h.close_csv()\n",
    "        if self.save_contexts:\n",
    "            self.csv_h_contexts.close_csv()\n",
    "        if self.contexts_file is not None:\n",
    "            self.f.close()\n",
    "\n",
    "\n",
    "    def compute_reward(self, action):\n",
    "        # print('ENV_TANK action[0]:\\n{}'.format(action[0]))\n",
    "        el = action[0]\n",
    "        # print('\\nCOMPUTE_REWARD el:\\n{}\\nobs:\\n{}\\n'.format(el, obs))\n",
    "        velht = self.vel * np.sin(el)\n",
    "        veldist = self.vel * np.cos(el)\n",
    "        self.t_impact = np.roots([0.5 * self.grav, velht, 0])[0]\n",
    "\n",
    "        self.dist_impact = veldist * self.t_impact\n",
    "        self.loc_impact = self.obs[0] + np.array(self.dist_impact)\n",
    "        \n",
    "        self.hit_miss_dist = np.subtract(self.obs[1], self.loc_impact)\n",
    "        dreward = np.abs(self.hit_miss_dist) / np.abs(self.obs[1] - self.obs[0])\n",
    "        # print('DIAG hit_miss_dist: {}, diff: {}, dreward: {}'.format(self.hit_miss_dist, self.obs[1] - self.obs[0], dreward))\n",
    "        # dreward = np.abs(self.hit_miss_dist)\n",
    "        treward = self.t_impact\n",
    "\n",
    "        # if self.hit_miss_dist < (self.dist * self.hitthresh):\n",
    "        #     reward = rewardbase + self.rewardmax\n",
    "        # else:\n",
    "        #     reward = rewardbase\n",
    "\n",
    "        return treward, dreward\n",
    "        # return dreward, treward\n",
    "\n",
    "\n",
    "    def compute_truthscore(self):  # accessing from outside\n",
    "        def t_hit_opt(x):\n",
    "            z = x - self.dist_impact /\\\n",
    "                (self.vel * np.cos(np.arcsin(-0.5 * self.grav * x / self.vel)))\n",
    "\n",
    "            return z\n",
    "\n",
    "        t_opt = fsolve(t_hit_opt, self.t_distmax / 2)[0]\n",
    "        tdiff = np.abs(self.t_impact - t_opt)\n",
    "        truthscore = np.array([self.hit_miss_dist, tdiff])\n",
    "\n",
    "        return truthscore, t_opt\n",
    "\n",
    "\n",
    "    def step(self, action, alpha=None):\n",
    "\n",
    "        m1, m2 = self.compute_reward(action)\n",
    "        truthscore, t_opt = self.compute_truthscore()\n",
    "        \n",
    "        if self.noise_dist == 'norm':\n",
    "            # m1 += np.random.normal(loc=0.0, scale=self.noise_var)\n",
    "            # m2 += np.random.normal(loc=0.0, scale=self.noise_var)\n",
    "            pert_m1 = np.random.normal(loc=0.0, scale=self.noise_var[0])\n",
    "            if m1 + pert_m1 > 0:\n",
    "                m1 -= pert_m1\n",
    "            elif m1 + pert_m1 <= 0:\n",
    "                m1 += pert_m1\n",
    "            if self.version == 2:\n",
    "                # m3 += np.random.normal(loc=0.0, scale=self.noise_var)\n",
    "                pert_m2 = np.random.normal(loc=0.0, scale=self.noise_var[1])\n",
    "                # print(pert_m1)\n",
    "                if m2 + pert_m2 > 0:\n",
    "                    m2 -= pert_m2\n",
    "                elif m2 + pert_m2 <= 0:\n",
    "                    m2 += pert_m2\n",
    "            \n",
    "        if self.create_log:\n",
    "            measure = {'step' : self.step_counter, 'context' : self.obs, 'action': action, 'reward' : m1, 'constraint_1': m2, 'alpha': alpha}\n",
    "            self.csv_h.addLine(measure)\n",
    "            \n",
    "        if self.contexts_file is not None:\n",
    "            if self.step_counter >= self.n_lines:\n",
    "                raise Exception('Context file ended.')\n",
    "            line = next(self.contexts_file)\n",
    "            for i in range(self.obs_dim):\n",
    "                self.obs[i] = float(line[i+1])\n",
    "        else:\n",
    "            # self.obs = self.observation_space.sample()\n",
    "            self.get_obs()\n",
    "        self.step_counter += 1\n",
    "        \n",
    "        if self.save_contexts:\n",
    "            # context2 = self.obs[2] if self.version == 2 else -1\n",
    "            measure = {'step' : self.step_counter, 'context0' : self.obs[0], 'context1': self.obs[1]}\n",
    "            self.csv_h_contexts.addLine(measure)\n",
    "        \n",
    "        obs = np.expand_dims(self.obs, axis=0)\n",
    "        reward = (m1, (m2)) if self.version == 2 else (m1)\n",
    "        done = False\n",
    "        info = {}\n",
    "\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    \n",
    "\n",
    "    def set_obs(self, obs):\n",
    "        self.obs = obs\n",
    "\n",
    "\n",
    "\n",
    "env_noise = {'dist' : 'norm', 'var' : [1e-1, 1e-4]}\n",
    "env = EnvTank(algo=None, noise=env_noise, timestamp='', contexts_file='', ver=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d7d878b-9984-4fc4-8e7a-a14800be3b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-26.217120315719512"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_scenario(obs0, action):\n",
    "    el = np.deg2rad(action)\n",
    "    \n",
    "    vel = 1000\n",
    "    grav = -9.81\n",
    "\n",
    "    velht = vel * np.sin(el)\n",
    "    veldist = vel * np.cos(el)\n",
    "    t_impact = np.roots([0.5 * grav, velht, 0])[0]\n",
    "    # print(t_impact)\n",
    "\n",
    "    \n",
    "\n",
    "    dist_impact = veldist * t_impact\n",
    "    loc_impact = obs0 + np.array(dist_impact)\n",
    "\n",
    "    return loc_impact\n",
    "\n",
    "\n",
    "loc_impact = compute_scenario(-39881.48, 24.68140488448044)\n",
    "37446.914 - loc_impact\n",
    "\n",
    "# 0.5 * 1019.3679918450559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4199487b-6e4e-4328-b9a9-bfc8faa4a2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate hits\n",
      "shtpos: 0.000 tgtpos: 72080.202, reward = (77.84264315787821, -4.001572083672233e-05)\n",
      "shtpos: 0.000 tgtpos: 101936.799, reward = (144.06253011321988, -0.00022408931992014578)\n",
      "shtpos: 0.000 tgtpos: 72080.202, reward = (188.16788895354088, -9.77277879876411e-05)\n",
      "shtpos: 0.000 tgtpos: -72080.202, reward = (188.25963591080333, -1.513572082976979e-05)\n",
      "shtpos: 0.000 tgtpos: -101936.799, reward = (144.17072579680985, -4.1059850193837235e-05)\n",
      "shtpos: 0.000 tgtpos: -72080.202, reward = (78.00464403535891, -0.00014542735069629752)\n",
      "shtpos: -500.000 tgtpos: 71580.202, reward = (77.94294461996029, -1.2167501649282842e-05)\n",
      "shtpos: -500.000 tgtpos: 101436.799, reward = (144.1160175883559, -3.336743273742668e-05)\n",
      "shtpos: -500.000 tgtpos: 71580.202, reward = (188.20523684524014, -2.051582637658009e-05)\n",
      "shtpos: 500.000 tgtpos: -71580.202, reward = (188.3233379823908, -8.540957393017248e-05)\n",
      "shtpos: 500.000 tgtpos: -101436.799, reward = (144.41570289321388, -6.536185954403606e-05)\n",
      "shtpos: 500.000 tgtpos: -71580.202, reward = (77.93260477258904, -7.42165020406442e-05)\n",
      "\n",
      "validate miss_over\n",
      "shtpos: 0.000 tgtpos: 72080.202, reward = (81.06743206568406, 0.03443576028905652)\n",
      "shtpos: 0.000 tgtpos: 101936.799, reward = (146.6498176933567, 0.000627891365906828)\n",
      "shtpos: 0.000 tgtpos: 72080.202, reward = (189.5342996488036, 0.035361733806415455)\n",
      "shtpos: 0.000 tgtpos: -72080.202, reward = (186.94884254287862, 0.03425250746963663)\n",
      "shtpos: 0.000 tgtpos: -101936.799, reward = (141.7112801973924, 0.0008072526277266374)\n",
      "shtpos: 0.000 tgtpos: -72080.202, reward = (74.75471511387188, 0.035493034786495285)\n",
      "shtpos: -500.000 tgtpos: 71580.202, reward = (81.17137846001005, 0.0341700857367182)\n",
      "shtpos: -500.000 tgtpos: 101436.799, reward = (146.69312622682764, 0.0006394032559617782)\n",
      "shtpos: -500.000 tgtpos: 71580.202, reward = (189.79243286674617, 0.035650671477123384)\n",
      "shtpos: 500.000 tgtpos: -71580.202, reward = (187.13496430451082, 0.03409524618207367)\n",
      "shtpos: 500.000 tgtpos: -101436.799, reward = (141.67346684080456, 0.0006529804110653633)\n",
      "shtpos: 500.000 tgtpos: -71580.202, reward = (74.84520343494427, 0.035430920647822495)\n",
      "\n",
      "validate miss_under\n",
      "shtpos: 0.000 tgtpos: 72080.202, reward = (74.8813136836951, 0.03552994371142648)\n",
      "shtpos: 0.000 tgtpos: 101936.799, reward = (141.7120482787488, 0.0005704827311181757)\n",
      "shtpos: 0.000 tgtpos: 72080.202, reward = (187.0154177992052, 0.034408386940008875)\n",
      "shtpos: 0.000 tgtpos: -72080.202, reward = (189.69039579307332, 0.03546583649635226)\n",
      "shtpos: 0.000 tgtpos: -101936.799, reward = (146.64774182284856, 0.0005789257911301238)\n",
      "shtpos: 0.000 tgtpos: -72080.202, reward = (81.3578397374509, 0.034326597838195146)\n",
      "shtpos: -500.000 tgtpos: 71580.202, reward = (74.78716994371689, 0.035544624999559134)\n",
      "shtpos: -500.000 tgtpos: 101436.799, reward = (141.70381625083385, 0.0007818012411372696)\n",
      "shtpos: -500.000 tgtpos: 71580.202, reward = (186.94659467122295, 0.03433050181521746)\n",
      "shtpos: 500.000 tgtpos: -71580.202, reward = (189.85059740493605, 0.03546239145785272)\n",
      "shtpos: 500.000 tgtpos: -101436.799, reward = (146.7451233815252, 0.000603978441324488)\n",
      "shtpos: 500.000 tgtpos: -71580.202, reward = (81.22149847186505, 0.03427742543052069)\n",
      "\n",
      "validate miss_big\n",
      "shtpos: 0.000 tgtpos: 72080.202, reward = (109.42726448747307, 0.28183624669361274)\n",
      "shtpos: 0.000 tgtpos: 101936.799, reward = (166.96324071641064, 0.060375860223185494)\n",
      "shtpos: 0.000 tgtpos: 72080.202, reward = (199.12805975975678, 0.4023854075062369)\n",
      "shtpos: 0.000 tgtpos: -72080.202, reward = (171.97640414472866, 0.2817071475773546)\n",
      "shtpos: 0.000 tgtpos: -101936.799, reward = (117.05360700264019, 0.060217296565396324)\n",
      "shtpos: 0.000 tgtpos: -72080.202, reward = (44.07975667918755, 0.4024811469083886)\n",
      "shtpos: -500.000 tgtpos: 71580.202, reward = (109.39237933654783, 0.2815231751939743)\n",
      "shtpos: -500.000 tgtpos: 101436.799, reward = (166.88559692341244, 0.06032537169767269)\n",
      "shtpos: -500.000 tgtpos: 71580.202, reward = (199.14805530698965, 0.40222207736706733)\n",
      "shtpos: 500.000 tgtpos: -71580.202, reward = (171.98556658621322, 0.28159051960453935)\n",
      "shtpos: 500.000 tgtpos: -101436.799, reward = (116.91626452075417, 0.060209715310443376)\n",
      "shtpos: 500.000 tgtpos: -71580.202, reward = (44.090686283443155, 0.4022568652229417)\n",
      "\n",
      "validate max_err\n",
      "shtpos: 0.000 tgtpos: 72080.202, reward = (144.1593539095584, 2.414034975323705)\n",
      "shtpos: 0.000 tgtpos: 101936.799, reward = (144.1477127023601, 1.9999598010636555)\n",
      "shtpos: 0.000 tgtpos: 72080.202, reward = (143.97208884192486, 2.4143483382792086)\n",
      "shtpos: 0.000 tgtpos: -72080.202, reward = (144.28745241147905, 0.41411662270227945)\n",
      "shtpos: 0.000 tgtpos: -101936.799, reward = (144.2777162521419, -0.00019436211856492928)\n",
      "shtpos: 0.000 tgtpos: -72080.202, reward = (144.20176580970644, 0.4142883078542387)\n",
      "shtpos: -500.000 tgtpos: 71580.202, reward = (143.96810970898244, 2.414065510893952)\n",
      "shtpos: -500.000 tgtpos: 101436.799, reward = (143.97364801558783, 1.9999093955341725)\n",
      "shtpos: -500.000 tgtpos: 71580.202, reward = (144.24652648013594, 2.4140225558777844)\n",
      "shtpos: 500.000 tgtpos: -71580.202, reward = (144.1872042487256, 0.4141333167335156)\n",
      "shtpos: 500.000 tgtpos: -101436.799, reward = (144.0656787148531, -1.550100930908342e-05)\n",
      "shtpos: 500.000 tgtpos: -71580.202, reward = (144.09899597459588, 0.414121341705938)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_env():\n",
    "    def test_loop(validate):\n",
    "        print('validate {}'.format(validate))\n",
    "        for scenpair in scenpairs:\n",
    "            shooterpos = scenpair[0]\n",
    "            actionideal = scenpair[1]\n",
    "            targetpos = compute_scenario(shooterpos, actionideal)\n",
    "            env.set_obs(np.array([shooterpos, targetpos]))\n",
    "            if validate == 'hits':\n",
    "                actionactual = actionideal\n",
    "            elif validate == 'miss_over':\n",
    "                actionactual = actionideal + 1\n",
    "            elif validate == 'miss_under':\n",
    "                actionactual = actionideal - 1\n",
    "            elif validate == 'miss_big':\n",
    "                actionactual = actionideal + 10\n",
    "            elif validate == 'max_err':\n",
    "                actionactual = 135\n",
    "            _, reward, _, _ = env.step([np.deg2rad(actionactual)])\n",
    "            print('shtpos: {:.3f} tgtpos: {:.3f}, reward = {}'.format(shooterpos, targetpos, reward))\n",
    "        print()\n",
    "            \n",
    "    scenpairs = [[0, 22.5], [0, 45], [0, 67.5],\n",
    "                [0, 112.5], [0, 135], [0, 157.5],\n",
    "                [-500, 22.5], [-500, 45], [-500, 67.5],\n",
    "                [500, 112.5], [500, 135], [500, 157.5],] \n",
    "    for validate in ['hits', 'miss_over', 'miss_under', 'miss_big', 'max_err']:\n",
    "        test_loop(validate)\n",
    "\n",
    "\n",
    "test_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b08349-02eb-4189-a927-591c477c9ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: [0.1, 0.0001]\n"
     ]
    }
   ],
   "source": [
    "var = [1e-1,1e-4]\n",
    "print('var: {}'.format(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c103df82-9bb2-41ae-8564-c4ef6aef1990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 0.0, denorm_act: 0.0\n",
      "action: 0.03125, denorm_act: 0.09817477042468103\n",
      "action: 0.0625, denorm_act: 0.19634954084936207\n",
      "action: 0.09375, denorm_act: 0.2945243112740431\n",
      "action: 0.125, denorm_act: 0.39269908169872414\n",
      "action: 0.15625, denorm_act: 0.4908738521234052\n",
      "action: 0.1875, denorm_act: 0.5890486225480862\n",
      "action: 0.21875, denorm_act: 0.6872233929727672\n",
      "action: 0.25, denorm_act: 0.7853981633974483\n",
      "action: 0.28125, denorm_act: 0.8835729338221293\n",
      "action: 0.3125, denorm_act: 0.9817477042468103\n",
      "action: 0.34375, denorm_act: 1.0799224746714913\n",
      "action: 0.375, denorm_act: 1.1780972450961724\n",
      "action: 0.40625, denorm_act: 1.2762720155208536\n",
      "action: 0.4375, denorm_act: 1.3744467859455345\n",
      "action: 0.46875, denorm_act: 1.4726215563702154\n",
      "action: 0.5, denorm_act: 1.5707963267948966\n",
      "action: 0.53125, denorm_act: 1.6689710972195777\n",
      "action: 0.5625, denorm_act: 1.7671458676442586\n",
      "action: 0.59375, denorm_act: 1.8653206380689396\n",
      "action: 0.625, denorm_act: 1.9634954084936207\n",
      "action: 0.65625, denorm_act: 2.061670178918302\n",
      "action: 0.6875, denorm_act: 2.1598449493429825\n",
      "action: 0.71875, denorm_act: 2.2580197197676637\n",
      "action: 0.75, denorm_act: 2.356194490192345\n",
      "action: 0.78125, denorm_act: 2.454369260617026\n",
      "action: 0.8125, denorm_act: 2.552544031041707\n",
      "action: 0.84375, denorm_act: 2.650718801466388\n",
      "action: 0.875, denorm_act: 2.748893571891069\n",
      "action: 0.90625, denorm_act: 2.84706834231575\n",
      "action: 0.9375, denorm_act: 2.945243112740431\n",
      "action: 0.96875, denorm_act: 3.043417883165112\n",
      "action: 1.0, denorm_act: 3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "def denormalize_action(action):\n",
    "    action_low = 0\n",
    "    action_high = 2 * np.deg2rad(90)\n",
    "    action = np.minimum(action, 1)\n",
    "    action = np.maximum(action, 0)\n",
    "    denorm_act = action * (action_high - action_low) + action_low\n",
    "    return denorm_act\n",
    "\n",
    "actions = np.linspace(0, 1, 33)\n",
    "for action in actions:\n",
    "    denorm_act = denormalize_action(action)\n",
    "    print('action: {}, denorm_act: {}'.format(action, denorm_act))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch113]",
   "language": "python",
   "name": "conda-env-pytorch113-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
